# nasa: team borderline solution

This documents the following submission

 - ID: `djj1LDTT`
 - Filename: `submission.csv`
 - Comment: `5e pre 29`
 - Submitted: `26 February 23:41`

This submission was mode on behalf of team `borderline` in the `NASA Harvest Field Boundary Detection Challenge` and placed third on the private leaderboard.

This solution was a team effort by team borderline with members

 - Hoang Van Truong
 - Tien Dung Le
 - Michiel George Ferreira

## Environment

Below are details of the environment.

### Python

```
python --version
Python 3.8.16
```

### Packages

The relevant packages are shown below. This is the contents of the `requirements.txt` file that is included in the solution.

```
rasterio==1.3.4
radiant_mlhub==0.5.5
scipy==1.8.1
sklearn
ttach==0.0.3
albumentations==1.3.0
# git+https://github.com/albumentations-team/albumentations
segmentation_models_pytorch==0.3.2
matplotlib
pandas
```

Note that this uses the latest albumentations version downloaded from git.

The models were built using torch. To install it, execute the following line. Note that this can also be done by executing the `torch-install.sh` script in the archive.

```
pip3 install -r requirements.txt
pip3 install torch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113
```

This install will also generate a lot of dependent installs of packages e.g. `numpy` and `pillow`.

### Competition data

Note that the competition data is not included in the archive. It *has to be copied in* in order to reproduce the solution.

Copy the data into the

```
nasa_rwanda_field_boundary_competition
```

directory. This directory is in the archive, but it is just an empty placeholder initially.

When done, it should look something like this.

```
|--- <solution root>
|       |--- nasa_rwanda_field_boundary_competition
|       |       |--- nasa_rwanda_field_boundary_competition_labels_train
|       |       |       |--- _common
|       |       |       |--- collection.json
|       |       |       |--- nasa_rwanda_field_boundary_competition_labels_train_00
|       |       |       |--- nasa_rwanda_field_boundary_competition_labels_train_01
|       |       |       |--- nasa_rwanda_field_boundary_competition_labels_train_02
|       |       |       |--- nasa_rwanda_field_boundary_competition_labels_train_03
|       |       |            ...
|       |       |--- nasa_rwanda_field_boundary_competition_labels_test
|       |       |       |--- collection.json
|       |       |       |--- nasa_rwanda_field_boundary_competition_source_test_00_2021_03
|       |       |       |--- nasa_rwanda_field_boundary_competition_source_test_00_2021_04
|       |       |       |--- nasa_rwanda_field_boundary_competition_source_test_00_2021_08
|       |       |            ...
|       |--- README.md
|       |--- ensemble-top-submit.ipynb
|            ...
```

## Solution review

The solution is based on the following pre-trained model

 - efficient net l2

The following variations were applied to this model. It was

 - trained as is
 - optimised with `decoder_attention_type='scse'`
 - augmented additionally using the `PiecewiseAffine` augmentation

We also tried many other models but they did not work as well.

### System

These models were optimised using A10's GPU infrastructure.

 - Linux
 - 24G NVIDIA GPU

It will take a few hours to run.

## Preprocessing

All channels were scaled between 0 and 1 using the minimum and maximum of the channel.

## Validation

We used 7 out-of-fold predictions to validate the models.

## Postprocessing

The out-of-fold predictions were used to test different True/False thresholds. We also used TTA with `HorizontalFlip` and `VerticalFlip` and weights

```
0.7 * model_pred + 0.3 * tta_model_pred
```

## Running the code

### Model

Once the data is ready, you can run the solution as follows.

```
python3 nhr-pytorch_m1.py
python3 nhr-pytorch_m2.py
python3 nhr-pytorch_m3.py
```

### Submission

We apply threshold 0.27 then voting ensemble on each cell. The final submission file can be generated by running the notebook

```
ensemble-top-submit.ipynb
```
